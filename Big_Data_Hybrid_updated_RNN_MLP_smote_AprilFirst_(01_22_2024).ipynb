{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LdXoibE_UaHs"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pandas\n",
        "import numpy\n",
        "import math\n",
        "import warnings\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from collections import Counter\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.ensemble import RandomForestClassifier,RandomForestRegressor\n",
        "from sklearn.metrics import roc_curve, auc, accuracy_score,roc_auc_score,mean_absolute_error,r2_score\n",
        "\n",
        "from scipy import stats\n",
        "import pickle\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_2GFOyKvHwO7"
      },
      "outputs": [],
      "source": [
        "import h5py as h5\n",
        "import scipy.io as sio\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from os import listdir\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Flatten, Embedding, Dropout, Activation, Reshape\n",
        "#from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, GlobalAveragePooling1D, TimeDistributed\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib as mat\n",
        "import sklearn as sk\n",
        "import imblearn as imb\n",
        "import xgboost as xgb\n",
        "import google.colab as co\n",
        "import scipy as sc\n",
        "print('pd', pd.__version__)\n",
        "print('np', np.__version__)\n",
        "print('mat', mat.__version__)\n",
        "print('sk', sk.__version__)\n",
        "print('tf', tf.__version__)\n",
        "print('sns', sns.__version__)\n",
        "print('imb', imb.__version__)\n",
        "print('xgb', xgb.__version__)\n",
        "print('co', co.__version__)\n",
        "print('sc', sc.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-fB97fuExhZ",
        "outputId": "f717bea4-a3c2-45e4-aee7-1f0b2b9534f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pd 1.3.5\n",
            "np 1.22.4\n",
            "mat 3.5.3\n",
            "sk 1.2.1\n",
            "tf 2.11.0\n",
            "sns 0.11.2\n",
            "imb 0.8.1\n",
            "xgb 1.7.4\n",
            "co 0.0.1a2\n",
            "sc 1.10.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wA5CBvZrINCW"
      },
      "outputs": [],
      "source": [
        "#dataset = pd.read_csv('sample_data/data_CKD_MI.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "GQFh9BcQQUNr",
        "outputId": "483ba81d-d2f1-42dd-faff-6edf8be123da"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-b797a540ce72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sample_data/data_CKD_bigdata_refined.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#df = dataset.dropna()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#print(df.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#df.describe()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'sample_data/data_CKD_bigdata_refined.csv'"
          ]
        }
      ],
      "source": [
        "dataset = pd.read_csv('sample_data/data_CKD_bigdata_refined.csv')\n",
        "print(dataset.shape)\n",
        "#df = dataset.dropna()\n",
        "#print(df.shape)\n",
        "#df.describe()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5YH9qd8LINIw"
      },
      "outputs": [],
      "source": [
        "#dataset = dataset.head(10000)\n",
        "# dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xzMIrR2kINMi"
      },
      "outputs": [],
      "source": [
        "dataset.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8CNu40DwJ80E"
      },
      "outputs": [],
      "source": [
        "dataset.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z-ot6qJbLzh6"
      },
      "outputs": [],
      "source": [
        "# dataset = dataset[dataset[ 'CREATININE ']<=15]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XbQGWH5opo6R"
      },
      "outputs": [],
      "source": [
        "dataset[['stage']] = dataset[['stage']].replace(to_replace={1:0,2:1,3:2,4:3,5:4})\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FBNXfnUF0zC4"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.layers import Dense, LSTM, Dropout, GRU, Bidirectional\n",
        "import keras.layers\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from imblearn.over_sampling import SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pIUUMkcGwRd-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "#from imblearn.under_sampling import RandomUnderSampler\n",
        "from collections import Counter\n",
        "from sklearn import metrics\n",
        "import math\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import mean_squared_error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f5Y1jrGLhR-V"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "from collections import Counter\n",
        "#Data preprocessing\n",
        "X = dataset.iloc[:,:-1].values\n",
        "y = dataset.iloc[:,-1].values\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.unique(y)"
      ],
      "metadata": {
        "id": "hiQbliu7LnxN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MzBcSiBgu7hk"
      },
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "counter = Counter(y)\n",
        "print('Before',counter)\n",
        "# oversampling the train dataset using SMOTE\n",
        "smt = SMOTE()\n",
        "#X_train, y_train = smt.fit_resample(X_train, y_train)\n",
        "X_sm, y_sm = smt.fit_resample(X, y)\n",
        "\n",
        "counter = Counter(y_sm)\n",
        "print('After',counter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S69ASFVAviHy"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_sm,y_sm, test_size=0.2, random_state = 2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_test[0])"
      ],
      "metadata": {
        "id": "d6B3JjO6AfzD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0i8Zj10BUuIQ"
      },
      "outputs": [],
      "source": [
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test  = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test[0]"
      ],
      "metadata": {
        "id": "HR4ZhkzhAw3_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "pickle.dump(scaler, open('ckd_hybrid_scaler.pkl', 'wb'))"
      ],
      "metadata": {
        "id": "AxE7BZY__vEq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "te8hct4A_v6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sg4HiGbCv975"
      },
      "outputs": [],
      "source": [
        "xg_reg = XGBRegressor()\n",
        "xg_reg.fit(X_train, y_train )\n",
        "y_train_hat = xg_reg.predict(X_train)\n",
        "train_r2 = metrics.r2_score(y_true=y_train, y_pred=y_train_hat)\n",
        "train_rmse = np.sqrt(mean_squared_error(y_train , y_train_hat))\n",
        "print ('R2: ',train_r2)\n",
        "print ('RMSE: ', train_rmse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Vo14Yn3upJb"
      },
      "outputs": [],
      "source": [
        "# from imblearn.combine import SMOTEENN\n",
        "# counter = Counter(y)\n",
        "# print('Before',counter)\n",
        "# # oversampling the train dataset using SMOTE + ENN\n",
        "# smenn = SMOTEENN()\n",
        "# X_smenn, y_smenn = smenn.fit_resample(X,y)\n",
        "# counter = Counter(y_smenn)\n",
        "# print('After',counter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gAwIQSVtvcCO"
      },
      "outputs": [],
      "source": [
        "#X_train,X_test,y_train,y_test=train_test_split(X_smenn, y_smenn, train_size=0.8, stratify = y_smenn, random_state=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "airL6oNdwoIK"
      },
      "outputs": [],
      "source": [
        "print(X_train.shape,y_train.shape)\n",
        "y_train = to_categorical(y_train,num_classes = 5,dtype=\"uint8\")\n",
        "print(y_train.shape)\n",
        "y_test = to_categorical(y_test,num_classes = 5,dtype =\"uint8\")\n",
        "print(y_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5YPTsprpiNZn"
      },
      "outputs": [],
      "source": [
        "X_train = np.reshape(X_train,(X_train.shape[0],X_train.shape[1],1))\n",
        "X_test = np.reshape(X_test,(X_test.shape[0],X_test.shape[1],1))\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # get the model SimpleRNN + MLP\n",
        "from keras.layers import Dense, SimpleRNN\n",
        "def evaluate_model_SimpleRNN(X_train, X_val, y_train, y_val):\n",
        "  model = SimpleRNN\n",
        "  timesteps=125\n",
        "  dims=4\n",
        "  model = Sequential()\n",
        "  model.add(SimpleRNN(units=32, input_shape=(X_train.shape[1],1), activation=\"relu\"))\n",
        "  model.add(Dense(256, kernel_initializer='he_uniform', activation='relu'))\n",
        "  model.add(Dense(128, kernel_initializer='he_uniform', activation='relu'))\n",
        "  model.add(Dense(64, kernel_initializer='he_uniform', activation='relu'))\n",
        "  model.add(Dense(5, kernel_initializer='he_uniform'))\n",
        "  model.compile(loss='mse', optimizer=Adam(lr = 0.001), metrics=['accuracy'])\n",
        "  history = model.fit(X_train, y_train, validation_data = (X_test,y_test), epochs=200, batch_size=5096, verbose=1)\n",
        "  return history, model\n"
      ],
      "metadata": {
        "id": "BpRxx1dNtMef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_folds = 1\n",
        "cv_scores, model_history = list(), list()\n",
        "model = tf.keras.Sequential()\n",
        "history, model= evaluate_model_SimpleRNN(X_train, X_test, y_train, y_test)\n",
        "# list all data in history\n",
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])"
      ],
      "metadata": {
        "id": "W-oi9_q3tnyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "pickle.dump(model, open('ckd_hybrid_model.pkl', 'wb'))\n"
      ],
      "metadata": {
        "id": "5UyN5ZdZfa_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CgDggC1dfcO8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_prob = model.predict(X_test)\n",
        "print(y_prob)\n",
        "y_classes = y_prob.argmax(axis=-1)\n",
        "print(y_classes)"
      ],
      "metadata": {
        "id": "HI9RM7Cdtuj5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_prob = model.predict(X_test)\n",
        "print(y_prob)\n",
        "y_classes = y_prob.argmax(axis=-1)\n",
        "print(y_classes)"
      ],
      "metadata": {
        "id": "c7Clmo0fjoFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "y_classes_1=y_test.argmax(axis=-1)\n",
        "mat = confusion_matrix(y_classes_1,y_classes)\n",
        "print(mat)\n",
        "pl= ConfusionMatrixDisplay(mat,display_labels=range(5))"
      ],
      "metadata": {
        "id": "yiFBIIC7tuhw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "FP = mat.sum(axis=0) - np.diag(mat)\n",
        "FN = mat.sum(axis=1) - np.diag(mat)\n",
        "TP = np.diag(mat)\n",
        "TN = mat.sum() - (FP + FN + TP)\n",
        "FP = FP.astype(float)\n",
        "FN = FN.astype(float)\n",
        "TP = TP.astype(float)\n",
        "TN = TN.astype(float)\n",
        "# Sensitivity, hit rate, recall, or true positive rate\n",
        "TPR = TP/(TP+FN)\n",
        "# Specificity or true negative rate\n",
        "TNR = TN/(TN+FP)\n",
        "# Precision or positive predictive value\n",
        "PPV = TP/(TP+FP)\n",
        "# Negative predictive value\n",
        "NPV = TN/(TN+FN)\n",
        "# Fall out or false positive rate\n",
        "FPR = FP/(FP+TN)\n",
        "# False negative rate\n",
        "FNR = FN/(TP+FN)\n",
        "# False discovery rate\n",
        "FDR = FP/(TP+FP)\n",
        "# Overall accuracy for each class\n",
        "ACC = (TP+TN)/(TP+FP+FN+TN)\n",
        "# print(TP)\n",
        "# print(TN)\n",
        "# print(FP)\n",
        "# print(FN)\n",
        "print(TPR)\n",
        "print(FPR)\n",
        "print(FNR)"
      ],
      "metadata": {
        "id": "ruzGCb-qt5Pj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "table = pd.DataFrame({'TPR':TPR,'FPR':FPR,'FNR':FNR,'ACCURACY':ACC},index = ['Stage 1', 'Stage 2', 'Stage 3','Stage 4','Stage 5'])\n",
        "table.round(3)"
      ],
      "metadata": {
        "id": "MVcp4YE2047r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oq47XJFcKPnl"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(y_classes_1,y_classes)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQiycBwgKU75"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
        "print(precision_score(y_classes_1,y_classes,average='micro'))\n",
        "print(recall_score(y_classes_1,y_classes,average=\"micro\"))\n",
        "print(f1_score(y_classes_1,y_classes,average=\"micro\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fsM4mFZyKYuX"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print('\\nClassification Report\\n')\n",
        "print(classification_report(y_classes_1,y_classes, target_names=['Stage 1', 'Stage 2', 'Stage 3','Stage 4','Stage 5']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "stUEHbeaOGbZ"
      },
      "outputs": [],
      "source": [
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "fig = plt.subplots(1,1, figsize = (10, 6))\n",
        "target_names=['Stage 1', 'Stage 2', 'Stage 3','Stage 4','Stage 5']\n",
        "df_cm = pd.DataFrame(mat,target_names,target_names)\n",
        "sn.set(font_scale= 1.5)\n",
        "sn.heatmap(df_cm,annot=True,annot_kws={\"size\":12},cmap='Blues',fmt='g')\n",
        "plt.xlabel('Predictions',fontsize=18)\n",
        "plt.ylabel('Actual',fontsize=18)\n",
        "plt.xticks(fontsize =14)\n",
        "plt.yticks(fontsize =14)\n",
        "plt.savefig('RNN-MLP_ConfusionMatrix.png', dpi=100)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "El3TBjY6KcXR"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.download('RNN-MLP_ConfusionMatrix.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9-xoGkF0Kge6"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig = plt.gcf()\n",
        "plt.style.use('seaborn-white')\n",
        "#fig = plt.subplots(1,1, figsize = (12, 8))\n",
        "fig.set_size_inches(11,8, forward=True)\n",
        "# fig = plt.figure()\n",
        "plt.plot(history.history['loss'],'b')\n",
        "plt.plot(history.history['val_loss'],'r')\n",
        "plt.title('RNN-MLP',fontsize = 24)\n",
        "plt.xlabel('Epochs',fontsize =22)\n",
        "plt.ylabel('Loss',fontsize = 22)\n",
        "plt.xticks(fontsize =18)\n",
        "plt.yticks(fontsize =18)\n",
        "plt.legend(['loss', 'validation loss'], loc='upper right')\n",
        "plt.draw()\n",
        "plt.savefig('RNN-MLP.png', dpi=300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T0jHdKw_LNgS"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.download('RNN-MLP.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pw8nEqRyLd_7"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
        "#plt.style.use('seaborn-white')\n",
        "\n",
        "target= ['Stage 1','Stage 2','Stage 3','Stage 4','Stage 5']\n",
        "\n",
        "# set plot figure size\n",
        "fig, c_ax = plt.subplots(1,1, figsize = (12, 8))\n",
        "\n",
        "# function for scoring roc auc score for multi-class\n",
        "def multiclass_roc_auc_score(y_classes_1, y_classes, average=\"macro\"):\n",
        "    lb = LabelBinarizer()\n",
        "    lb.fit(y_classes_1)\n",
        "    y_test = lb.transform(y_classes_1)\n",
        "    y_pred = lb.transform(y_classes)\n",
        "\n",
        "    for (idx, c_label) in enumerate(target):\n",
        "        fpr, tpr, thresholds = roc_curve(y_test[:,idx].astype(int), y_pred[:,idx])\n",
        "        c_ax.plot(fpr, tpr, label = '%s (AUC:%0.2f)'  % (c_label, auc(fpr, tpr)))\n",
        "    c_ax.plot(fpr, fpr, 'b-', label = 'Random Guessing')\n",
        "    return roc_auc_score(y_test, y_pred, average=average)\n",
        "print('ROC AUC score:', multiclass_roc_auc_score(y_classes_1, y_classes))\n",
        "c_ax.legend(fontsize=18,)\n",
        "#c_ax.legend()\n",
        "c_ax.set_xlabel('False Positive Rate',fontsize = 22)\n",
        "c_ax.set_ylabel('True Positive Rate',fontsize = 22)\n",
        "plt.title('RNN-MLP',fontsize = 24)\n",
        "plt.xticks(fontsize =18)\n",
        "plt.yticks(fontsize =18)\n",
        "plt.savefig('RNN-MLP_AUC.png', dpi=300)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SK0My9dwizwG"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.download('RNN-MLP_AUC.png')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}